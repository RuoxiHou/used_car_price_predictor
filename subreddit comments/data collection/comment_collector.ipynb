{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Praw in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (7.7.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from Praw) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from Praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from Praw) (0.58.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->Praw) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->Praw) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->Praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->Praw) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->Praw) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->Praw) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install Praw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import praw\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = getpass.getpass()\n",
    "client_secret = getpass.getpass()\n",
    "user_agent = getpass.getpass()#\"Scraper 1.0 by /u/Few_Prior6804\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id = client_id,\n",
    "    client_secret = client_secret,\n",
    "    user_agent = user_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['Volkswagen', 'Audi', 'Porsche', 'Alfa Romeo', 'Bmw', 'Ford',\n",
    "       'Peugeot', 'Mercedes Benz', 'Jeep', 'Hyundai', 'Å koda', 'Fiat',\n",
    "       'Mazda', 'Seat', 'Toyota', 'Citroen', 'Renault', 'Kia', 'Volvo',\n",
    "       'Opel', 'Land Rover', 'Honda', 'Suzuki', 'Saic', 'Lexus', 'Smart',\n",
    "       'Nissan', 'Jaguar', 'Mitsubishi', 'Abarth', 'Mini', 'Mclaren',\n",
    "       'Cupra', 'Ssangyong', 'Maserati', 'Subaru', 'Dodge', 'Chevrolet',\n",
    "       'Lancia', 'Bentley', 'Hummer', 'Dacia', 'Tesla', 'Ds Automobiles',\n",
    "       'Alpine', 'Ferrari', 'Isuzu', 'Dr', 'Rolls Royce', 'Chrysler',\n",
    "       'Lamborghini', 'Saab', 'Alpina', 'Cadillac', 'Ineos', 'Karma',\n",
    "       'Lincoln', 'Byd', 'Seres', 'Infiniti', 'Aston Martin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to check if the subreddits are the same names as they are case sensitive, and not to mention that there is also space in between some words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name_list = ['Volkswagen', 'Audi', 'Porsche', 'AlfaRomeo', 'BMW', 'Ford',\n",
    "       'peugeot', 'mercedes_benz', 'Jeep', 'Hyundai', 'skoda', 'Fiat',\n",
    "       'mazda', 'seat', 'Toyota', 'Citroen', 'Renault', 'kia', 'Volvo',\n",
    "       'opel', 'LandRover', 'Honda', 'Suzuki', 'saic', 'Lexus', 'SmartCar',\n",
    "       'Nissan', 'Jaguar', 'mitsubishi', 'abarth', 'MINI', 'mclaren',\n",
    "       'CupraFormentor', 'SsangYong', 'Maserati', 'subaru', 'Dodge', 'Chevrolet',\n",
    "       'lancia', 'Bentley', 'Hummer', 'Dacia', 'teslamotors', 'DSAutomobiles',\n",
    "        'Ferrari', 'Isuzu',  'rollsroyce', 'chrysler',\n",
    "       'lamborghini', 'saab', 'Alpina', 'Cadillac', 'ineosgrenadier',\n",
    "       'lincoln', 'BYD',  'infiniti', 'AstonMartin']\n",
    "\n",
    "       # There's no subreddit that is made for non-F1 Alpine, so this one is skipped\n",
    "       # DR Automobiles is too local to have an English subreddit, therefore it's also skipped\n",
    "       # Subreddit for Karma Automotive/ Seres is also not found, at least not wihtin the big communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subreddit_name in subreddit_name_list:\n",
    "    comments = set()  # Initialize set to collect comments\n",
    "    for submission in reddit.subreddit(subreddit_name).hot(limit=200):\n",
    "        for comment in submission.comments.list():\n",
    "            if not isinstance(comment, praw.models.MoreComments):\n",
    "                comments.add(comment.body)\n",
    "    print(f\"Number of comments collected from {subreddit_name}: {len(comments)}\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({'Comments': list(comments)})\n",
    "    \n",
    "    # Add 'Make' column\n",
    "    df['Make'] = subreddit_name\n",
    "    \n",
    "    # Write DataFrame to CSV\n",
    "    df.to_csv(f'comments_on_reddit_{subreddit_name}.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
